{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperdash import monitor_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特に前処理について.\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from absl import flags\n",
    "import absl.logging as _logging  # pylint: disable=unused-import\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from randaugment import policies as found_policies\n",
    "from randaugment import augmentation_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_TARNAME = \"cifar-10-python.tar.gz\"\n",
    "CIFAR_DOWNLOAD_URL = \"https://www.cs.toronto.edu/~kriz/\" + CIFAR_TARNAME\n",
    "SVHN_DOWNLOAD_URL = \"http://ufldl.stanford.edu/housenumbers/{}_32x32.mat\"\n",
    "\n",
    "DOWNLOAD_DATA_FOLDER = \"downloaded_data\"\n",
    "MERGE_DATA_FOLDER = \"merged_raw_data\"\n",
    "\n",
    "random_seed = np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sup_filename(split, sup_size=-1):\n",
    "  if split == \"test\":\n",
    "    return \"test.tfrecord\"\n",
    "  elif split == \"train\" or split == \"dev\":\n",
    "    if sup_size == -1:\n",
    "      return \"{}-full.tfrecord\".format(split, sup_size)\n",
    "    else:\n",
    "      return \"{}-size_{:d}.tfrecord\".format(split, sup_size)\n",
    "\n",
    "def format_unsup_filename(aug_copy_num):\n",
    "  return \"unsup-{:d}.tfrecord\".format(aug_copy_num)\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list(value)))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=list(value)))\n",
    "\n",
    "\n",
    "def get_raw_data_filenames(split):\n",
    "    if split == \"train\":\n",
    "        return [\"data_batch_%d\" % i for i in xrange(1, 6)]\n",
    "    elif split == \"test\":\n",
    "      return [\"test_batch\"]\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def read_pickle_from_file(filename):\n",
    "  with tf.gfile.Open(filename, \"rb\") as f:\n",
    "    if sys.version_info >= (3, 0):\n",
    "      data_dict = pickle.load(f, encoding=\"bytes\")\n",
    "    else:\n",
    "      data_dict = pickle.load(f)\n",
    "  return data_dict\n",
    "\n",
    "\n",
    "def obtain_tfrecord_writer(out_path, shard_cnt):\n",
    "  tfrecord_writer = tf.python_io.TFRecordWriter(\n",
    "      \"{}.{:d}\".format(out_path, shard_cnt))\n",
    "  return tfrecord_writer\n",
    "\n",
    "\n",
    "def save_tfrecord(example_list, out_path, max_shard_size=4096):\n",
    "  shard_cnt = 0\n",
    "  shard_size = 0\n",
    "  record_writer = obtain_tfrecord_writer(out_path, shard_cnt)\n",
    "  for example in example_list:\n",
    "    if shard_size >= max_shard_size:\n",
    "      record_writer.close()\n",
    "      shard_cnt += 1\n",
    "      record_writer = obtain_tfrecord_writer(out_path, shard_cnt)\n",
    "      shard_size = 0\n",
    "    shard_size += 1\n",
    "    record_writer.write(example.SerializeToString())\n",
    "  record_writer.close()\n",
    "  tf.logging.info(\"saved {} examples to {}\".format(len(example_list), out_path))\n",
    "\n",
    "\n",
    "def save_merged_data(images, labels, split, merge_folder):\n",
    "  with tf.gfile.Open(\n",
    "      os.path.join(merge_folder, \"{}_images.npy\".format(split)), \"wb\") as ouf:\n",
    "    np.save(ouf, images)\n",
    "  with tf.gfile.Open(\n",
    "      os.path.join(merge_folder, \"{}_labels.npy\".format(split)), \"wb\") as ouf:\n",
    "    np.save(ouf, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:found all merged files\n",
      "all_exist:True\n",
      "INFO:tensorflow:downloading dataset\n"
     ]
    }
   ],
   "source": [
    "all_exist = True\n",
    "download_folder = os.path.join(DOWNLOAD_DATA_FOLDER)\n",
    "merge_folder = os.path.join(MERGE_DATA_FOLDER)\n",
    "for split in [\"train\", \"test\"]:\n",
    "    for field in [\"images\", \"labels\"]:\n",
    "        if not tf.gfile.Exists(os.path.join(merge_folder, \"{}_{}.npy\".format(split, field))):\n",
    "            all_exist = False\n",
    "if all_exist:\n",
    "    tf.logging.info(\"found all merged files\")\n",
    "print('all_exist:' + str(all_exist))\n",
    "tf.logging.info(\"downloading dataset\")\n",
    "tf.gfile.MakeDirs(download_folder)\n",
    "tf.gfile.MakeDirs(merge_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-6-6790cd9f9af3>:3: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    }
   ],
   "source": [
    "#if FLAGS.task_name == 'cifar10'以下の話\n",
    "tf.contrib.learn.datasets.base.maybe_download(\n",
    "    CIFAR_TARNAME, download_folder, CIFAR_DOWNLOAD_URL)\n",
    "tarfile.open(os.path.join(download_folder, CIFAR_TARNAME), \"r:gz\").extractall(download_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"test\"]:\n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "    for filename in get_raw_data_filenames(split):\n",
    "        cur_data = read_pickle_from_file(\n",
    "            os.path.join(download_folder, \"cifar-10-batches-py\", filename))\n",
    "        labels_list += [cur_data[b\"labels\"]]\n",
    "        images_list += [cur_data[b\"data\"]]\n",
    "    images = np.concatenate(images_list, 0)\n",
    "    labels = np.concatenate(labels_list, 0)\n",
    "    images = images.reshape([-1, 3, 32, 32])\n",
    "    images = images.transpose(0, 2, 3, 1)\n",
    "    save_merged_data(images, labels, split, merge_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多分iterableにimageとlabelを取り出す.最後まで, 可能な限り\n",
    "def get_data_by_size_lim(images, labels, sup_size, return_rest=False):\n",
    "    chosen_images = images[:sup_size]\n",
    "    chosen_labels = labels[:sup_size]\n",
    "    rest_images = images[sup_size:]\n",
    "    rest_labels = labels[sup_size:]\n",
    "    if return_rest:\n",
    "        return chosen_images, chosen_labels, rest_images, rest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_sup_data(chosen_images, chosen_labels, split, sup_size=-1):\n",
    "    chosen_images = chosen_images / 255.0\n",
    "    mean, std = [0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]\n",
    "    chosen_images = (chosen_images - mean) / std\n",
    "    example_list = []\n",
    "    for image, label in zip(chosen_images, chosen_labels):\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                \"image\": _float_feature(image.reshape(-1)),\n",
    "                \"label\": _int64_feature(label.reshape(-1))\n",
    "            }))\n",
    "        example_list += [example]\n",
    "    out_path = os.path.join(output_base_dir, format_sup_filename(split, sup_size))\n",
    "    tf.logging.info(\">>saving {} {} examples to {}\".format(len(example_list), split, out_path))\n",
    "    save_tfrecord(example_list, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_and_dump_sup_data(sub_set_data, split, sup_size=-1):\n",
    "    images = sub_set_data[\"images\"]\n",
    "    labels = sub_set_data[\"labels\"]\n",
    "    if sup_size != -1:\n",
    "        chosen_images, chosen_labels = get_data_by_size_lim(\n",
    "            images, labels, sup_size)\n",
    "    else:\n",
    "        chosen_images = images\n",
    "        chosen_labels = labels\n",
    "    process_and_save_sup_data(chosen_images, chosen_labels, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised dataのみをrand augmentする.\n",
    "def proc_and_dump_unsup_data(sub_set_data, aug_copy_num):\n",
    "    ori_images = sub_set_data[\"images\"].copy()\n",
    "    image_idx = np.arange(len(ori_images))\n",
    "    np.random.shuffle(image_idx)\n",
    "    ori_images = ori_images[image_idx]\n",
    "    ori_images = ori_images / 255.0\n",
    "    mean, std = [0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]\n",
    "    ori_images = (ori_images - mean) / std\n",
    "    aug_policies = found_policies.randaug_policies()\n",
    "    example_list = []\n",
    "    for image in ori_images:\n",
    "        chosen_policy = aug_policies[np.random.choice(\n",
    "            len(aug_policies))]\n",
    "        #この段階で, chosen_policyは2個の要素を持っている.\n",
    "        aug_image = augmentation_transforms.apply_policy(\n",
    "            chosen_policy, image)\n",
    "        aug_image = augmentation_transforms.cutout_numpy(aug_image)\n",
    "        #ここで条件式を投げて, aug_imageが一定の閾値以下であれば3回目のaugmentationを加える.\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                \"ori_image\": _float_feature(image.reshape(-1)),\n",
    "                \"aug_image\": _float_feature(aug_image.reshape(-1)),\n",
    "            }))\n",
    "        example_list += [example]\n",
    "    out_path = os.path.join(output_base_dir, format_unsup_filename(aug_copy_num),)\n",
    "    save_tfrecord(example_list, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = {}\n",
    "    merge_folder = os.path.join(MERGE_DATA_FOLDER)\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        with tf.gfile.Open(\n",
    "            os.path.join(merge_folder, \"{}_images.npy\".format(split)), 'rb') as inf:\n",
    "            images = np.load(inf)\n",
    "        with tf.gfile.Open(\n",
    "            os.path.join(merge_folder, \"{}_labels.npy\".format(split)), 'rb') as inf:\n",
    "            labels = np.load(inf)\n",
    "        data[split] = {\"images\":images, \"labels\":labels}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dataset_by_randaugment_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_dir = \"dataset_by_randaugment_v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randaug(sub_set_data, aug_copy_num):\n",
    "    ori_images = sub_set_data[\"images\"].copy()\n",
    "    image_idx = np.arange(len(ori_images))\n",
    "    np.random.shuffle(image_idx)\n",
    "    ori_images = ori_images[image_idx]\n",
    "    ori_images = ori_images / 255.0\n",
    "    mean, std = [0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784]\n",
    "    ori_images = (ori_images - mean) / std\n",
    "    aug_policies = found_policies.randaug_policies()\n",
    "    example_list = []\n",
    "    i = 0\n",
    "    for image in ori_images:\n",
    "        chosen_policy = aug_policies[np.random.choice(len(aug_policies))]\n",
    "        aug_image = augmentation_transforms.apply_policy(chosen_policy, image)\n",
    "        aug_image = augmentation_transforms.cutout_numpy(aug_image)\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                \"ori_image\": _float_feature(image.reshape(-1)),\n",
    "                \"aug_image\": _float_feature(aug_image.reshape(-1)),\n",
    "            }))\n",
    "        example_list += [example]\n",
    "        i += 1\n",
    "        if i%1000 == 0:\n",
    "            print(str(i) + \"done!\")\n",
    "    out_path = os.path.join(output_base_dir, format_unsup_filename(aug_copy_num),)\n",
    "    save_tfrecord(example_list, out_path)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-0.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-1.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-2.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-3.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-4.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-5.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-6.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-7.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n",
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-8.tfrecord\n",
      "INFO:tensorflow:trans_list: ['Invert', 'Cutout', 'Sharpness', 'AutoContrast', 'Posterize', 'ShearX', 'TranslateX', 'TranslateY', 'ShearY', 'Rotate', 'Equalize', 'Contrast', 'Color', 'Solarize', 'Brightness']\n",
      "1000done!\n",
      "2000done!\n",
      "3000done!\n",
      "4000done!\n",
      "5000done!\n",
      "6000done!\n",
      "7000done!\n",
      "8000done!\n",
      "9000done!\n",
      "10000done!\n",
      "11000done!\n",
      "12000done!\n",
      "13000done!\n",
      "14000done!\n",
      "15000done!\n",
      "16000done!\n",
      "17000done!\n",
      "18000done!\n",
      "19000done!\n",
      "20000done!\n",
      "21000done!\n",
      "22000done!\n",
      "23000done!\n",
      "24000done!\n",
      "25000done!\n",
      "26000done!\n",
      "27000done!\n",
      "28000done!\n",
      "29000done!\n",
      "30000done!\n",
      "31000done!\n",
      "32000done!\n",
      "33000done!\n",
      "34000done!\n",
      "35000done!\n",
      "36000done!\n",
      "37000done!\n",
      "38000done!\n",
      "39000done!\n",
      "40000done!\n",
      "41000done!\n",
      "42000done!\n",
      "43000done!\n",
      "44000done!\n",
      "45000done!\n",
      "46000done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47000done!\n",
      "48000done!\n",
      "49000done!\n",
      "50000done!\n",
      "INFO:tensorflow:saved 50000 examples to dataset_by_randaugment_v5/unsup-9.tfrecord\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    randaug(data[\"train\"], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([0.7951000, 0.7915000, 0.7878999])\n",
    "B = np.array([0.7678000, 0.7512000, 0.7695000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=4.508157842784919, pvalue=0.04584683489561074)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
